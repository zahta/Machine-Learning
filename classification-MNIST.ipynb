{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on the MNIST dataset\n",
    "by [Zahra Taheri](https://github.com/zata213/Applied_Machine_Learning_S20_Assignments) (5 June 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST into NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zahra\\MNIST\n"
     ]
    }
   ],
   "source": [
    "#Define path to the directory containing MNIST files\n",
    "\n",
    "%cd \\Users\\Zahra\\MNIST\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train_data and train_labels\n",
    "train_data, train_labels= loadlocal_mnist(\n",
    "        images_path='train-images.idx3-ubyte', \n",
    "        labels_path='train-labels.idx1-ubyte')\n",
    "\n",
    "#load test_data and test_labels\n",
    "test_data, test_labels= loadlocal_mnist(\n",
    "        images_path='t10k-images.idx3-ubyte', \n",
    "        labels_path='t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 60000 x 784\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions: %s x %s' % (train_data.shape[0], train_data.shape[1]))\n",
    "#print('\\n1st row', train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)   # 28*28=784\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = train_data[40000]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary,interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits:  0 1 2 3 4 5 6 7 8 9\n",
      "labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
     ]
    }
   ],
   "source": [
    "print('Digits:  0 1 2 3 4 5 6 7 8 9')\n",
    "print('labels: %s' % np.unique(train_labels))\n",
    "print('Class distribution: %s' % np.bincount(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datas as csv files\n",
    "\n",
    "#np.savetxt(fname='train_images.csv', X=train_data, delimiter=',', fmt='%d')\n",
    "#np.savetxt(fname='train_labels.csv', X=train_labels, delimiter=',', fmt='%d')\n",
    "\n",
    "#np.savetxt(fname='test_images.csv', X=test_data, delimiter=',', fmt='%d')\n",
    "#np.savetxt(fname='test_labels.csv', X=test_labels, delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape dataset to have a single color channel\n",
    "\n",
    "#train_data=train_data.reshape((train_data.shape[0],28,28,1))\n",
    "#test_data=test_data.reshape((test_data.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode target values\n",
    "\n",
    "#def onehot_labels(labels):\n",
    "#    return np.eye(10)[labels]\n",
    "\n",
    "\n",
    "#y_train=onehot_labels(train_labels)\n",
    "#y_test=onehot_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_labels\n",
    "y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values\n",
    "\n",
    "def prep_pix(train, test):\n",
    "    train_norm = train.astype('float32') # convert from integers to floats\n",
    "    test_norm = test.astype('float32')\n",
    "    train_norm = train_norm / 255.0 # normalize to range 0-1\n",
    "    test_norm = test_norm / 255.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test=prep_pix(train_data,test_data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KJx14EzKk91"
   },
   "source": [
    "## Select and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7mo7fJhiiJJ"
   },
   "source": [
    "##### SVM Classifier, Decision Tree Classifier, SGD Classifier,  Logistic Regression Classifier and Random Forrests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pymX3eW_iiIL"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "svm_clf = SVC(random_state=42)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "sgd_clf = SGDClassifier(max_iter=15, tol=-np.infty,loss='hinge', random_state=42)\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_h_clf = VotingClassifier(\n",
    "    estimators=[('svc',svm_clf),('dt',tree_clf),('lr', log_clf),('rf', rf_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "040NaH99iiIj",
    "outputId": "6e9ad36a-e4a4-4e69-9dea-0419ad558333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.9792\n",
      "DecisionTreeClassifier 0.8663\n",
      "SGDClassifier 0.9125\n",
      "LogisticRegression 0.9202\n",
      "RandomForestClassifier 0.958\n",
      "VotingClassifier 0.9626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (svm_clf,tree_clf, sgd_clf, log_clf, rf_clf, vot_h_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "niijYFGviiIz",
    "outputId": "f210eeb3-8547-4f36-c00f-be7afef08a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.9668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "vot_s_clf = VotingClassifier(\n",
    "     estimators=[('svc',svm_clf),('dt',tree_clf),('lr', log_clf),('rf', rf_clf)],\n",
    "    voting='soft')\n",
    "\n",
    "vot_s_clf.fit(X_train, y_train)\n",
    "y_pred = vot_s_clf.predict(X_test)\n",
    "\n",
    "print(vot_s_clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7mo7fJhiiJJ"
   },
   "source": [
    "#### Bagging Classifier, Random Forrests Classifier and Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5SXr9u0iiJL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier 0.8593\n",
      "RandomForestClassifier 0.958\n",
      "ExtraTreesClassifier 0.9501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42), n_estimators=500,\n",
    "    max_samples=150, bootstrap=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "estimators = [bag_clf, rf_clf, extra_trees_clf]\n",
    "\n",
    "for clf in estimators:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron Classifier and AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.9786\n",
      "AdaBoostClassifier 0.9646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "mlp_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=10), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "\n",
    "estimators = [mlp_clf, ada_clf]\n",
    "\n",
    "for clf in estimators:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 0.9656\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf=XGBClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(xgb_clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifiers                    | Accuracy |\n",
    "|--------------------------------|----------|\n",
    "| Bagging Classifier             | 0.8593   |\n",
    "| Decision Tree Classifier       | 0.8663   |\n",
    "| SGD Classifier                 | 0.9125   |\n",
    "| Logistic Regression Classifier | 0.9202   |\n",
    "| Extra Trees Classifier         | 0.9501   |\n",
    "| Random Forest Classifier       | 0.958    |\n",
    "| Voting Classifier (hard)       | 0.9626   |\n",
    "| AdaBoost Classifier            | 0.9646   |\n",
    "| XGBoost Classifier             | 0.9656   |\n",
    "| Voting Classifier (soft)       | 0.9668   |\n",
    "| MLP Classifier                 | 0.9786   |\n",
    "| SVM Classifier                 | 0.9792   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
