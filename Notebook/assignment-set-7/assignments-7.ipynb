{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions of some exercises of the book \"Understanding Machine Learning-from Theory to Algorithms\"      \n",
    "by [Zahra Taheri](https://github.com/zata213/Applied_Machine_Learning_S20_Assignments) (18 April 2020)\n",
    "\n",
    "#### Chapter 9 (Linear Predictors)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise $9.1$**\n",
    "\n",
    "Firstly, we prove that for all $c\\in \\mathbb{R}$, $|c|=\\min_{a\\geq 0}{a}$ such that $-a\\leq c\\leq a$. If $c\\geq 0$ then obviously $c=|c|=\\min_{a\\geq 0} a$ such that $0\\leq c\\leq a$. If $c<0$ then $-c>0$ and with the latter discussion, $-c=|c|=|-c|=\\min_{a\\geq 0} a$ such that $0\\leq -c\\leq a$. Therefore, for all $c\\in \\mathbb{R}$, $|c|=\\min_{a\\geq 0}{a}$ such that $-a\\leq c\\leq a$. So, for all $i\\in [m]$, if we consider $a_i=|\\langle w,x_i\\rangle -y_i|$, then we have\n",
    "\n",
    "$$-a_i\\leq \\langle w,x_i\\rangle -y_i\\leq a_i.$$\n",
    "\n",
    "Therefore, we want to write the following problem as a linear program:\n",
    "$$\n",
    "\\min \\sum_{i=1}^m{a_i}\\\\\n",
    "\\text{s.t.  } \\langle w,x_i\\rangle -a_i\\leq y_i\n",
    "\\text{  and  } -\\langle w,x_i\\rangle -a_i\\leq -y_i, \\text{ for all }i\\in[m]. \\ \\ \\ \\ \\ (1)\n",
    "$$\n",
    "\n",
    "Let \n",
    "\n",
    "\\begin{equation*}\n",
    "A=\\left(\n",
    "\\begin{array}{cc}\n",
    "x_1^T &  \\\\\n",
    "\\vdots &  -I_m\\\\\n",
    "x_m^T &  \\\\\n",
    "-x_1^T &  \\\\\n",
    "\\vdots &  -I_m\\\\\n",
    "-x_m^T & \n",
    "\\end{array} \\right),\n",
    "w'=\\left(w_1,\\ldots,w_d,a_1,\\ldots,a_m\\right)^T,\n",
    "y=\\left(y_1,\\ldots,y_m,-y_1,\\ldots,-y_m\\right)^T.\n",
    "\\end{equation*}\n",
    "\n",
    "Then by (1) and with the above notations we have\n",
    "$$Aw'\\leq y.$$\n",
    "Therefore, we can write the ERM problem of linear regression with respect to the absolute\n",
    "value loss function as the following linear program:\n",
    "$$\n",
    "\\min a w'\\\\\n",
    "Aw'\\leq y,\n",
    "$$\n",
    "where $a=(\\overbrace{0,\\ldots,0}^d,\\overbrace{1,\\dots,1}^m)^T$.\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise $9.3$**\n",
    "\n",
    "Let $m$ be an arbitrary positive integer. Suppose that $d=m$ and for all $i\\in [m]$, $x_i=e_i$ and $y_i=1$. Then $R=\\max_i \\Vert x_i\\Vert=1$. If $w^*=(1,\\ldots,1)^T$, then for all $i\\in [m]$, $y_i\\langle w^*,x_i\\rangle=1$ and $\\Vert w^*\\Vert^2=m$, and so, using the notation in Theorem $9.1$, we have $B=\\min\\{\\Vert w\\Vert : \\forall i\\in [m], y_i\\langle w,x_i\\rangle\\geq 1\\}=\\sqrt{m}$. Therefore, $(RB)^2=m$ and by Theorem $9.1$, the Perceptron algorithm stops after at most $m$ iterations.\n",
    "\n",
    "On the other hand by the Perceptron algorithm, we have\n",
    "$$\n",
    "w^{(1)}=0\\\\ w^{(2)}=e_1\\\\ w^{(3)}=e_1+e_2\\\\\\vdots\\\\ w^{(m)}=\\sum_{i=1}^{m-1}e_i\\\\ w^{(m+1)}=(1,\\ldots,1)^T=w^*.\n",
    "$$\n",
    "If we assume that $sign(0)=-1$ then for all $i\\in [m]$, $\\langle w^{(i)},x_i\\rangle=0$ and so $sign(\\langle w^{(i)},x_i\\rangle)\\not=y_i$. Also by Theorem $9.1$, when the Perceptron algorithm stops it holds that for all $i\\in [m], y_i\\langle w^{(t)},x_i\\rangle>0$. So the Perceptron algorithm stops after $m$ iterations and then we obtain $w^*=(1,\\ldots,1)^T$ with the desired condition $y_i\\langle w^*,x_i\\rangle=1$, for all $i\\in [m]$.\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise $9.4$**\n",
    "\n",
    "Suppose that $x_1,\\ldots,x_m$ are all positive examples such that for all $i\\in [m]$, $x_i=(a,b,1)$ and $\\Vert x_i\\Vert^2=R^2$. Since the examples have the same labels, $(x_1,1),\\ldots,(x_m,1)$ is separable. Let $w^*=(0,0,1)$. Then obviously $y_i\\langle w^*,x_i\\rangle\\geq 1$, for all $i\\in [m]$ and we have $B=\\Vert w^*\\Vert=1$. Then, the Perceptron algorithm stops after at most $(RB)^2=R^2$ iterations, and when it stops it holds that for all $i\\in [m], \\langle w^{(t)},x_i\\rangle>0$.\n",
    "\n",
    "Now we want to construct $m=R^2$ positive examples on which the upper bound of Theorem $9.1$ equals $R^2$ and the perceptron algorithm is bound to make $R^2$ mistakes. Let $x_1:=(a_1,0,1)$ such that $a_1=\\sqrt{R^2-1}$. Suppose that in iteration $t$ of the Perceptron algorithm, the new example $x_t=(a,b,1)$ be such that \n",
    "1.  $\\Vert x_t\\Vert^2=R^2$, and\n",
    "2.  $\\langle w^{(t)},x_t\\rangle=0$.     \n",
    "\n",
    "We want to prove that as long as $t\\leq R^2$, we can meet the above two desired conditions.\n",
    "\n",
    "Let $t\\leq R^2$. It is easy to see that if the above two conditions hold, for some $\\alpha ,\\beta \\in \\mathbb{R}$ we have\n",
    "\n",
    "$$w^{(t)}=(\\alpha,\\beta,t-1). \\ \\ \\ \\ \\ \\ \\ \\ (1)$$ \n",
    "\n",
    "Also by condition $\\langle w^{(t)},x_t\\rangle=0$, the inequality $(9.4)$ in the proof of Theorem $9.1$ holds with equality and we have \n",
    "$$\\Vert w^{(t)}\\Vert^2=\\Vert w^{(t-1)}\\Vert^2+R^2.$$\n",
    "Now since $\\Vert w^{(1)}\\Vert^2=0$, if we use above equation recursively for $t$ iterations, we obtain that \n",
    "\n",
    "$$\\Vert w^{(t)}\\Vert^2=(t-1)R^2.\\ \\ \\ \\ \\ (2)$$\n",
    "\n",
    "Therefore, by equations (1) and (2) we have $\\alpha^2+\\beta^2+(t-1)^2=(t-1)R^2$. If $\\beta\\not=0$, then without loss of generality we may rotate $w^{(t)}$ with respect to the $z$ axis and consider $w^{(t)}=(\\alpha,0,t-1)$. Therefore, with the discussion above we have $\\alpha=\\sqrt{(t-1)R^2-(t-1)^2}$ and so  $w^{(t)}=(\\sqrt{(t-1)R^2-(t-1)^2},0,t-1)$.\n",
    "\n",
    "Now let $a:=-\\frac{t-1}{\\alpha}$ and $x_t:=\\left(a,b,1\\right)$, where $b\\in \\mathbb{R}$. Then it is easy to see that $\\langle w^{(t)},x_t\\rangle=0$. Therefore, if $b:=\\sqrt{R^2-a^2-1}$, then $\\Vert x_t\\Vert^2=R^2$ and so, the two desired conditions hold. We just need to prove that $R^2-a^2-1\\geq 0$ or equivalently $a^2+1\\leq R^2$. Since $t\\leq R^2$, we have $R^2-t+1\\geq 1$ and so\n",
    "$$\n",
    "a^2+1=\\frac{(t-1)^2}{\\alpha^2}+1=\\frac{(t-1)R^2}{(t-1)R^2-(t-1)^2}=\\frac{R^2}{R^2-t+1}\\leq R^2.\n",
    "$$\n",
    "\n",
    "This completes the proof.\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise $9.6$**\n",
    "\n",
    "1. Suppose that $\\mathcal{B}_d=\\{B_{v,r}:v\\in\\mathbb{R}^d \\text{ and } r>0\\}$ such that $B_{v,r}$ is a closed ball of center $v$ and radius $r$ in $\\mathbb{R}^d$, i.e., \n",
    "    \\begin{equation*} \n",
    "    B_{v,r}(x)=\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "     1 & \\mbox{if $\\Vert x-v\\Vert \\leq r$}\\\\\n",
    "    0 & \\mbox{otherwise}\n",
    "    \\end{array} \n",
    "     \\right.\n",
    "    \\end{equation*}\n",
    "   Also suppose that $C=\\{x_1,\\ldots,x_m\\}$ is shattered by $\\mathcal{B}_d$. If $y=(y_1,\\ldots,y_m)$ is an arbitrary vector of labels of $C$, then there exists $B_{v,r}\\in \\mathcal{B}_d$ such that for all $i\\in [m]$ we have $B_{v,r}(x_i)=y_i$. By definition of $B_{v,r}$, $y_i=1$ for some $i\\in [m]$, if and only if $\\Vert x_i-v\\Vert \\leq r$ if and only if\n",
    "   $$\n",
    "   \\sum_{j=1}^d{{x_i}_j}^2-2\\sum_{j=1}^d{{x_i}_j}{v_j}+\\sum_{j=1}^d{v_j}^2-r^2\\leq 0,\n",
    "   $$\n",
    "   where $x_i=({x_i}_1,\\ldots,{x_i}_d)^T$ and $v=(v_1,\\ldots,v_d)^T$, or equivalently \n",
    "   \n",
    "   $$\n",
    "   \\langle w,x\\rangle+b\\leq 0,\n",
    "   $$\n",
    "   \n",
    "   where $w:=(-2 v_1,\\ldots,-2 v_d,1)^T$, $x:=({x_i}_1,\\ldots,{x_i}_d,\\Vert x_i\\Vert^2)^T$ and $b:=\\sum_{j=1}^d{v_j}^2-r^2$.\n",
    "   \n",
    "   Let $\\mathcal{L}_{d+1}$ be the class of halfspaces in $\\mathbb{R}^{d+1}$ and consider the mapping $\\phi:\\mathbb{R}^d\\rightarrow \\mathbb{R}^{d+1}$ defined by $\\phi(a)=(a_1,\\ldots,a_d,\\Vert a\\Vert^2)^T$. With the discussion above and the assumption $sign(0)=1$, if $x_1,\\ldots,x_m$ are shattered by $\\mathcal{B}_d$ then $\\phi(x_1),\\ldots,\\phi(x_m)$ are shattered by $\\mathcal{L}_{d+1}$. Therefore,\n",
    "   $$\n",
    "   VCdim(\\mathcal{B}_d)\\leq VCdim(\\mathcal{L}_{d+1})=d+2.\n",
    "   $$\n",
    "\n",
    "2. Let $C=\\{0,e_1,\\ldots,e_d\\}$. We want to show that if $\\varnothing\\not=C'\\subseteq C$, then there exists $B_{v,r}\\in \\mathcal{B}_d$ such that for all $x\\in C'$,  $B_{v,r}(x)=1$, and for all $x\\in C\\setminus C'$,  $B_{v,r}(x)=0$.\n",
    "\n",
    "    Let $v:=\\sum_{x\\in C'}x$. Therefore,\n",
    "    \\begin{equation*} \n",
    "    \\Vert x-v\\Vert=\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "     \\sqrt{|C'|-1} & \\mbox{if $x\\in C'$ and $x\\not=0$}\\\\\n",
    "   \\sqrt{|C'|} & \\mbox{if $x=0$}\\\\\n",
    "   \\sqrt{|C'|+1} & \\mbox{if $x\\in C\\setminus C'$ and $x\\not=0$}\n",
    "    \\end{array} \n",
    "     \\right.\n",
    "    \\end{equation*}\n",
    "    If $0\\not\\in C'$, then let $r:=\\sqrt{|C'|-1}$. Otherwise, let $r:=\\sqrt{|C'|}$. With the discussion above, it is easy to see that $C$ is shattered by $\\mathcal{B}_d$ and so $d+1\\leq  VCdim(\\mathcal{B}_d)$.\n",
    "    \n",
    "Therefore by parts $1$ and $2$ we have\n",
    "$$\n",
    "d+1\\leq  VCdim(\\mathcal{B}_d)\\leq d+2.\n",
    "$$\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referential Note:** After thinking on each exercise for at least one day, to solve **some parts** of **some exercises**, I got hints from a [solution manual](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/exercises.html) of the book by Alon Gonen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
