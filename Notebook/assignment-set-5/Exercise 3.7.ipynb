{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise $3.7$**\n",
    "\n",
    "The Bayes Optimal Predictor: Given any probability distribution $\\mathcal{D}$ over $X\\times \\{0,1\\}$, the Bayes Optimal Predictor is the following label predicting function from $X$ to $\\{0,1\\}$: \n",
    "$$ \n",
    "f_{\\mathcal{D}}(x)=\\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\mbox{if $\\mathbb{P}\\left[y = 1|x\\right]\\geq 1/2$}\\\\\n",
    "0 & \\mbox{otherwise}\n",
    "\\end{array} \n",
    " \\right.\n",
    "$$\n",
    "\n",
    "We want to verify that for every probability distribution $\\mathcal{D}$, the Bayes optimal predictor $f_{\\mathcal{D}}$ is optimal. It means that for every classifier $g:X\\rightarrow \\{0,1\\}$, $L_{\\mathcal{D}}(f_{\\mathcal{D}})\\leq L_{\\mathcal{D}}(g)$. Note that for every classifier $g$, \n",
    "\n",
    "$$L_{\\mathcal{D}}(g)=\\mathbb{P}\\left[\\{g(X)\\not=Y\\}\\right]=\\mathbb{E}_X\\left[\\mathbb{P}\\left[\\{g(X)\\not=Y|X=x\\}\\right]\\right].$$\n",
    "\n",
    "We prove that $\\mathbb{P}\\left[\\{g(X)\\not=Y\\}\\right]\\geq \\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)\\not=Y\\}\\right]$.\n",
    "\n",
    "It is easy to see that for every classifier $g:X\\rightarrow \\{0,1\\}$ we have:\n",
    "\n",
    "$$\\mathbb{P}\\left[\\{g(X)\\not=Y|X=x\\}\\right]=1-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]=1-\\mathbb{P}\\left[\\{g(X)=1,Y=1|X=x\\}\\right]-\\mathbb{P}\\left[\\{g(X)=0,Y=0|X=x\\}\\right]$$\n",
    "Also we have\n",
    " 1.  $\\mathbb{P}\\left[\\{g(X)=1,Y=1|X=x\\}\\right]=\\mathbb{P}\\left[\\{g(X)=1|X=x\\}\\right]\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right]$\n",
    " \n",
    " 2.  $\\mathbb{P}\\left[\\{g(X)=0,Y=0|X=x\\}\\right]=\\mathbb{P}\\left[\\{g(X)=0|X=x\\}\\right]\\mathbb{P}\\left[\\{Y=0|X=x\\}\\right]$\n",
    "\n",
    "Note that if $g(x)=1$ then $\\mathbb{P}\\left[\\{g(X)=1|X=x\\}\\right]=1$ and if $g(x)=0$ then $\\mathbb{P}\\left[\\{g(X)=1|X=x\\}\\right]=0$. Also if $g(x)=0$ then $\\mathbb{P}\\left[\\{g(X)=0|X=x\\}\\right]=1$ and if $g(x)=1$ then $\\mathbb{P}\\left[\\{g(X)=0|X=x\\}\\right]=0$.\n",
    "\n",
    "Therefore\n",
    "$$1-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]=1-(\\mathbb{1}_{g(x)=1}\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right]+\\mathbb{1}_{g(x)=0}\\mathbb{P}\\left[\\{Y=0|X=x\\}\\right])$$\n",
    "\n",
    "So we have:\n",
    "\n",
    "$$\\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)=Y|X=x\\}\\right]-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]=\\\\\n",
    "\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right](\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-\\mathbb{1}_{g(x)=1})+\n",
    "\\mathbb{P}\\left[\\{Y=0|X=x\\}\\right](\\mathbb{1}_{f_{\\mathcal{D}}(x)=0}-\\mathbb{1}_{g(x)=0})\n",
    "$$\n",
    "\n",
    "Since $\\mathbb{P}\\left[\\{Y=0|X=x\\}\\right]=1-\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right]$ and for every classifier $g:X\\rightarrow \\{0,1\\}$, $\\mathbb{1}_{g(x)=0}=1-\\mathbb{1}_{g(x)=1}$, we have:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)=Y|X=x\\}\\right]-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]=\\\\\n",
    "\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right](\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-\\mathbb{1}_{g(x)=1})+\n",
    "(1-\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right])(\\mathbb{1}_{f_{\\mathcal{D}}(x)=0}-\\mathbb{1}_{g(x)=0})=\\\\\n",
    "\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right](\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-\\mathbb{1}_{g(x)=1})+\n",
    "(1-\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right])(1-\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-1+\\mathbb{1}_{g(x)=1})=\\\\\n",
    "\\left(2\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right]-1\\right)\\left(\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-\\mathbb{1}_{g(x)=1}\\right)\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)=Y|X=x\\}\\right]-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]=\n",
    "\\left(2\\mathbb{P}\\left[\\{Y=1|X=x\\}\\right]-1\\right)\\left(\\mathbb{1}_{f_{\\mathcal{D}}(x)=1}-\\mathbb{1}_{g(x)=1}\\right)\n",
    "$$\n",
    "\n",
    "So by the definition of the Bayes predictor, for all $x\\in X$ we have \n",
    "\n",
    "$$\\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)=Y|X=x\\}\\right]-\\mathbb{P}\\left[\\{g(X)=Y|X=x\\}\\right]\\geq 0$$\n",
    "\n",
    "Hence, for all $x\\in X$ we have\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left[\\{g(X)\\not=Y|X=x\\}\\right]\\geq \\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)\\not=Y|X=x\\}\\right]\n",
    "$$\n",
    "\n",
    "Since $\\mathbb{E}_{X,Y}[f(X,Y)]=\\mathbb{E}_X \\mathbb{E}_{Y|X=x}[f(X,Y) | X=x]$, by the latter inequality we have:\n",
    " \n",
    "$$L_{\\mathcal{D}}(g)=\\mathbb{E}_{(x,y)\\sim \\mathcal{D}}\\left[\\mathbb{1}_{g(x)\\not=y}\\right]=\n",
    "\\mathbb{E}_{x\\sim \\mathcal{D}_{X}}\\left[\\mathbb{E}_{y\\sim \\mathcal{D}_{Y|x}}\\left[\\mathbb{1}_{g(x)\\not=y}|X=x\\right]\\right]=\\mathbb{E}_{x\\sim \\mathcal{D}_{X}}\\left[\\mathbb{P}\\left[\\{g(X)\\not=Y|X=x\\}\\right]\\right]\\geq \\mathbb{E}_{x\\sim \\mathcal{D}_{X}}\\left[\\mathbb{P}\\left[\\{f_{\\mathcal{D}}(X)\\not=Y|X=x\\}\\right]\\right]=L_{\\mathcal{D}}(f_{\\mathcal{D}})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "---------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
